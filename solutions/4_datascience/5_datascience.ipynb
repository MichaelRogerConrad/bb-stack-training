{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Science\n",
    "[Data Science](https://en.wikipedia.org/wiki/Data_science) is an **interdisciplinary field** about processes and systems to **extract knowledge or insights from data** in various forms, either structured or unstructured.\n",
    "\n",
    "The term should read **data craftsmenship** because it is more about expertise and experience in applying knowlegde and algorithms from various fields and sciences. \n",
    "\n",
    "Let's not call it an art :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommendations\n",
    "We want to build a **recommendation engine** based on the sales data we collected. A recommendation engine allows you to recommend new products to users which he most likely be interested it. The recommender can work in 2 ways: \n",
    "\n",
    "1. **Product perspective**: You are buying or liking or looking at this product, but we can also recommend these other products. \n",
    "1. **User perspective**: Other users like you, prefer these products too.\n",
    "\n",
    "But do mind '[how you target](http://www.nytimes.com/2012/02/19/magazine/shopping-habits.html)' ;-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark MLlib\n",
    "Spark's [Machine Learning Library (MLlib)](http://spark.apache.org/docs/latest/mllib-guide.html#sparkml-high-level-apis-for-ml-pipelines) has the necessary tools to build recommenders. \n",
    "\n",
    "We will use the *amount of products sold per customer* as an **expression of preference for a given product**. \n",
    "\n",
    "If we skimm through MLlib's available algorithms, [collaborative filtering](http://spark.apache.org/docs/latest/mllib-collaborative-filtering.html) using [alternating least squares (ALS)](http://dl.acm.org/citation.cfm?id=1608614) seems very appropriate, because you can also train the algorithm using **implicit feedback** (*amount of products sold*). \n",
    "\n",
    "So let's pick-up where we started in the previous chapter: read the **sales dataframe**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(key=u'20061101-IN', customer_age=21, customer_gender=u'Male', customer_key=22102, customer_marital_status=u'Unknown', customer_name=u'Duncan A. Lewis', customer_state=u'TX', date=u'2006-11-01T00:00:00.000000Z', employee_gender=u'Male', employee_job_title=u'Head of PR', employee_key=1056, employee_name=u'Raja Weaver', employee_state=u'TX', price=62.0, product_category=u'Food', product_department=u'Canned Goods', product_description=u'Brand #28472 canned corn', product_key=9483, product_price=174.0, product_version=1, quantity=2.0, store_key=239, store_name=u'Store239', store_state=u'IN', tender_type=u'Credit', transaction=u'3821456', transaction_type=u'purchase', rainfall=19.02670669555664, temp_avg=160.3333282470703, temp_max=216.57142639160156, temp_min=74.26262664794922)]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql.types import *\n",
    "from pyspark.sql.functions import *\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "\n",
    "sqlContext = SQLContext(sc)\n",
    "\n",
    "sales_schema = StructType([ \\\n",
    "    StructField(\"key\", StringType(), True), \\\n",
    "    StructField(\"customer_age\", IntegerType(), True), \\\n",
    "    StructField(\"customer_gender\", StringType(), True), \\\n",
    "    StructField(\"customer_key\", IntegerType(), True), \\\n",
    "    StructField(\"customer_marital_status\", StringType(), True), \\\n",
    "    StructField(\"customer_name\", StringType(), True), \\\n",
    "    StructField(\"customer_state\", StringType(), True), \\\n",
    "    StructField(\"date\", StringType(), True), \\\n",
    "    StructField(\"employee_gender\", StringType(), True), \\\n",
    "    StructField(\"employee_job_title\", StringType(), True), \\\n",
    "    StructField(\"employee_key\", IntegerType(), True), \\\n",
    "    StructField(\"employee_name\", StringType(), True), \\\n",
    "    StructField(\"employee_state\", StringType(), True), \\\n",
    "    StructField(\"price\", FloatType(), True), \\\n",
    "    StructField(\"product_category\", StringType(), True), \\\n",
    "    StructField(\"product_department\", StringType(), True), \\\n",
    "    StructField(\"product_description\", StringType(), True), \\\n",
    "    StructField(\"product_key\", IntegerType(), True), \\\n",
    "    StructField(\"product_price\", FloatType(), True), \\\n",
    "    StructField(\"product_version\", IntegerType(), True), \\\n",
    "    StructField(\"quantity\", FloatType(), True), \\\n",
    "    StructField(\"store_key\", IntegerType(), True), \\\n",
    "    StructField(\"store_name\", StringType(), True), \\\n",
    "    StructField(\"store_state\", StringType(), True), \\\n",
    "    StructField(\"tender_type\", StringType(), True), \\\n",
    "    StructField(\"transaction\", StringType(), True), \\\n",
    "    StructField(\"transaction_type\", StringType(), True), \\\n",
    "    StructField(\"rainfall\", FloatType(), True), \\\n",
    "    StructField(\"temp_avg\", FloatType(), True), \\\n",
    "    StructField(\"temp_max\", FloatType(), True), \\\n",
    "    StructField(\"temp_min\", FloatType(), True) \\\n",
    "])\n",
    "\n",
    "df = sqlContext.read \\\n",
    "    .format('com.databricks.spark.csv') \\\n",
    "    .load('/data/views/daily_weather_sales_per_state', schema = sales_schema)\n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(key=u'20061208-NV', customer_age=26, customer_gender=u'Female', customer_key=24548, customer_marital_status=u'Divorced', customer_name=u'Betty X. Lewis', customer_state=u'IN', date=u'2006-12-08T00:00:00.000000Z', employee_gender=u'Male', employee_job_title=u'Greeter', employee_key=7780, employee_name=u'Theodore Fortin', employee_state=u'WI', price=489.0, product_category=u'Food', product_department=u'Dairy', product_description=u'Brand #59900 margarine', product_key=19950, product_price=242.0, product_version=3, quantity=8.0, store_key=214, store_name=u'Store214', store_state=u'NV', tender_type=u'Cash', transaction=u'3924716', transaction_type=u'purchase', rainfall=9.71875, temp_avg=85.9473648071289, temp_max=184.9942169189453, temp_min=32.410404205322266, product_pkey=199503)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pkey = udf(lambda key, version: key * 10 + version, IntegerType())\n",
    "df = df.withColumn('product_pkey', pkey(df.product_key, df.product_version))\n",
    "    \n",
    "df.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn our sales data into customer preferences\n",
    "Now, build the ratings-like customer's **preference dataframe** but *aggregating the amount of units sold per product*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(customer_key=8508, product_pkey=131751, rating=1.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences = df \\\n",
    "    .groupBy('customer_key', 'product_pkey') \\\n",
    "    .agg(sum('quantity').alias('rating'))\n",
    "\n",
    "preferences.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(customer_key=8508, product_pkey=131751, rating=1.0)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preferences.where('customer_key = 8508 and product_pkey = 131751').take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=8508, product=131751, rating=1.0)]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ALS requires a dataset of Ratings\n",
    "ratings = preferences.map(lambda l: Rating(int(l[0]), int(l[1]), float(l[2])))\n",
    "ratings.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the algorithm\n",
    "Next we will have to train a **model using the ALS algorithm**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split the ratings dataset into a training (75%) and test (25%) dataset \n",
    "splits = ratings.randomSplit([0.75, 0.25], 11)\n",
    "\n",
    "training = splits[0].cache()\n",
    "test = splits[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build the recommendation model using ALS\n",
    "model = ALS.trainImplicit(training, rank=10, iterations=20, alpha=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Squared Error = 38.5277430927\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on training data\n",
    "testdata = test.map(lambda p: (p[0], p[1]))\n",
    "predictions = model.predictAll(testdata).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "ratesAndPreds = test.map(lambda r: ((r[0], r[1]), r[2])).join(predictions)\n",
    "MSE = ratesAndPreds.map(lambda r: (r[1][0] - r[1][1])**2).mean()\n",
    "print(\"Mean Squared Error = \" + str(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[((29640, 69551), 0.30281999165789997),\n",
       " ((36101, 97851), 0.16908753265968166),\n",
       " ((45522, 122711), 0.165085118658801),\n",
       " ((19017, 33971), 0.15391220559712881),\n",
       " ((941, 54171), 0.14609363603144015)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions.sortBy(lambda r: -r[1]).take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Save and load model\n",
    "model.save(sc, \"/data/models/als_1\")\n",
    "sameModel = MatrixFactorizationModel.load(sc, \"/data/models/als_1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now make some recommendations\n",
    "Recommend 5 products for user <xyz>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(product_pkey=49971, product_description=u'Brand #14942 golf clubs')]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products_schema = StructType([ \\\n",
    "    StructField(\"product_key\", IntegerType(), True), \\\n",
    "    StructField(\"product_version\", IntegerType(), True), \\\n",
    "    StructField(\"product_description\", StringType(), True), \\\n",
    "    StructField(\"product_category\", StringType(), True), \\\n",
    "    StructField(\"product_department\", StringType(), True), \\\n",
    "    StructField(\"product_price\", IntegerType(), True), \\\n",
    "])\n",
    "\n",
    "products = sqlContext.read \\\n",
    "    .format('com.databricks.spark.csv') \\\n",
    "    .load('/data/raw/retail/products', schema = products_schema)\n",
    "    \n",
    "products = products.withColumn('product_pkey', pkey(products.product_key, products.product_version))\n",
    "products = products.select('product_pkey', 'product_description')\n",
    "products.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(29640, 11)]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_key = 29640\n",
    "user_data = products.map(lambda p: (user_key, p.product_pkey))\n",
    "user_data.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Rating(user=29640, product=38641, rating=0.5487241048313785),\n",
       " Rating(user=29640, product=112681, rating=0.43379049582455226),\n",
       " Rating(user=29640, product=195121, rating=0.3921101470760089),\n",
       " Rating(user=29640, product=56871, rating=0.3863316168798289),\n",
       " Rating(user=29640, product=185791, rating=0.36577378307444935)]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations = sameModel.predictAll(user_data).sortBy(lambda r: -r[2])\n",
    "recommendations.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[38641, 112681, 195121, 56871, 185791]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommended_products = recommendations.map(lambda r: r.product)\n",
    "recommended_products.take(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.4.1)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
