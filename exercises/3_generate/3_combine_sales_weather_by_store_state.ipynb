{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine sales and weather data\n",
    "Up until now, we have read the weather and retail data from the database and stored it on HDFS. After that we transformed the data we read so it made more sense and was easier to process in subsequent steps. We generated views to group the data by date and state so the logical next step would be to combine the two views we created into one large view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data\n",
    "We will need to load the two views we created earlier.\n",
    "\n",
    "### The weather view\n",
    "During our previous processing, we stored the weather view in HDFS. Now we need to read it back again from **/data/views/daily_weather_per_state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "weather = sc.sequenceFile(\"/data/views/daily_weather_per_state\")\n",
    "weather.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The sales view\n",
    "The same goes for the sales view. That one is located at **/data/views/daily_sales_per_state**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sales = sc.sequenceFile(\"/data/views/daily_sales_per_state\")\n",
    "sales.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Joining sales and weather into one\n",
    "The time has come to join our two views together."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "joined = \n",
    "joined.take(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Storing the joined result\n",
    "We are going to save the results as a CSV file. This means we will have to restructure the records into lines which we can then store into a text file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def to_line(v):\n",
    "    rec = [];\n",
    "    rec.append(v[0])\n",
    "    \n",
    "    sales_data = v[1][0];\n",
    "    for key in sorted(sales_data):\n",
    "        rec.append(str(sales_data[key]));\n",
    "    \n",
    "    weather_data = v[1][1];\n",
    "    for key in sorted(weather_data):\n",
    "        if key != 'date':\n",
    "            rec.append(str(weather_data[key]));\n",
    "         \n",
    "    return ','.join(rec);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "formatted = \n",
    "formatted.take(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "formatted.saveAsTextFile('/data/views/daily_weather_sales_per_state')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pySpark (Spark 1.4.1)",
   "language": "python",
   "name": "pyspark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
